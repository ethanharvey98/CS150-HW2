{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A sequential generative model for MNIST\n",
        "\n",
        "The PixelCNN [1] generates images through the conditional probabilities. The model fits the probability $p(x_i | x_{<i})$.\n",
        "* During training: we need to from training pairs (x_{<i}, x_i) and use these pairs to train the model.\n",
        "* During generation, we loop through $i=0, \\ldots, d-1$, and generate each pixel $x_i$ through a sample $p(x_i | x_{<i})$.\n",
        "\n",
        "\n",
        "**Work to complete**:\n",
        "1. [2 points] create the CNN model. You may want to start with a simple network and then gradually increase its depth/width.\n",
        "2. [2 points] set up the training loop. Please remember to call the function \"form_conditional_samples\"\n",
        "3. [4 points] train the model. After training, please show the test loss in each epoch. The test loss should descent with the training epochs.\n",
        "4. [2 points] show the generate examples.\n",
        "5. [5 points] There are two sub-questions below. Please answer these two questions before or after the coding part.\n",
        "\n",
        "\n",
        "**Extra notes**:\n",
        "1. Please use LLMs (Gemini associated with the notebook or others) to generate the code for each cell. Free versions of LLMs are sufficient for the work. You can use Claude or GPT by typing the prompts there and copying the code back to the notebook.\n",
        "\n",
        "2. With your Tufts email, you can apply for GPU computation credits. Please do apply for the credits early.\n",
        "\n",
        "3. You are reponsible for the correctness of the the code, not the LLM.\n",
        "\n",
        "\n",
        "\n",
        "[1] Aäron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray Kavukcuoglu. 2016. Conditional image generation with PixelCNN decoders. In Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16). Curran Associates Inc., Red Hook, NY, USA, 4797–4805."
      ],
      "metadata": {
        "id": "o58i0xyiCwFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sub-question 5.1** (2 points). Suppose we want the model to predict $x_i$ at the $i$-th step, why are we so strict about not letting the model using entries after $i$? What's the consequence if we forget to mask out all bits after $i - 1$?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "LosxIVQI7OTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sub-question 5.3** (3 points). Suppose we take a random batch of test instances and select random locations for each test instance to compute a test loss for plotting and monitoring the training progress. Is the test loss an unbiased estimation of the log-likelihood of test instances? Please given an answer and explain your reason. Please remember: our goal is to maximize the log-likelihood of *test* data to avoid overfitting.\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "bos4Y9qc8hxk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d018953"
      },
      "source": [
        "## Download and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxyvSYrrxGpR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "44960cfd-c5bf-4e06-fe1a-6e1e258b77ae"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "train_images = trainset.data.numpy()\n",
        "test_images = testset.data.numpy()\n",
        "\n",
        "# Let's work on the simple case and make mnist binary data\n",
        "\n",
        "train_images = (train_images > 128).astype(np.float32)\n",
        "test_images = (test_images > 128).astype(np.float32)\n",
        "\n",
        "# show a few images from the training set\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12, 3))\n",
        "for idx, img in enumerate(train_images[:4]):\n",
        "    axes[idx].imshow(img, cmap='gray')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the mdoel"
      ],
      "metadata": {
        "id": "qvxpkWzsGSn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please create your model here"
      ],
      "metadata": {
        "id": "xs9eRpmWGRN8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Forming random batches\n",
        "\n",
        "For each instance x, get the training example: $(x_{<i}, x_i)$, with $x_{<i}$ being the neural network input, and $x_i$ being the predicting target.\n"
      ],
      "metadata": {
        "id": "_pqGXgfdG6qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given a batch of images, randomly generate positions to create samples for conditional distributions\n",
        "\n",
        "# Let x_batch be a batch of samples with shape [B, d]\n",
        "# Randomly generate B integers in range [0, d), each integer pointing to one of d elements.\n",
        "# This element is the target, and the elements before this element are conditions, and the elements afterward are not observed\n",
        "#\n",
        "\n",
        "\n",
        "def form_conditional_samples(x_batch):\n",
        "    \"\"\"\n",
        "    Convert a batch of B images to conditional samples.\n",
        "    First generate B integers, each of which indexes the target, while the pixels before the index\n",
        "    are the condition, and pixels after the index are not observed.\n",
        "    Then for each instance, create three channels.\n",
        "      - The first channel is 1 if the original value is 0 and before the target,\n",
        "      - The second channel is 1 if the original value is 1 and before the target,\n",
        "      - The third channel is 1 if the pixels are the target or after the target pixel.\n",
        "    The target is a vector containing the targe of each image in the batch\n",
        "    \"\"\"\n",
        "    B, H, W = x_batch.shape\n",
        "    N = H * W  # total pixels\n",
        "    x_flat = x_batch.view(B, N)\n",
        "\n",
        "    # Random target index for each image\n",
        "    target_idx = torch.randint(low=0, high=N, size=(B,))\n",
        "\n",
        "    # Initialize output tensor: [B, 3, H, W]\n",
        "    out = torch.zeros(B, 3, H, W, dtype=torch.float32)\n",
        "    target = torch.zeros(B, dtype=torch.float32)\n",
        "\n",
        "    for i in range(B):\n",
        "        idx = target_idx[i]\n",
        "        # Pixels before target\n",
        "        before = x_flat[i, :idx]\n",
        "        # Pixels after (including) target\n",
        "        after = x_flat[i, idx:]\n",
        "\n",
        "        # First channel: 1 if pixel is 0 and before target\n",
        "        ch1 = (before == 0).float()\n",
        "        # Second channel: 1 if pixel is 1 and before target\n",
        "        ch2 = (before == 1).float()\n",
        "        # Third channel: 1 for target and after\n",
        "        ch3 = torch.ones_like(after)\n",
        "\n",
        "        # Combine channels and reshape\n",
        "        out[i, 0, :idx] = ch1\n",
        "        out[i, 1, :idx] = ch2\n",
        "        out[i, 2, idx:] = ch3\n",
        "\n",
        "        target[i] = x_flat[i, idx]\n",
        "\n",
        "    return out, target\n"
      ],
      "metadata": {
        "id": "dC60AzV8HDe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now please generate the dataloader that load batches of training examples. Each batch should be converted using the function above.\n"
      ],
      "metadata": {
        "id": "uo59JOzENCJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we form the training loop"
      ],
      "metadata": {
        "id": "mQOmFZbtKUZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "\n",
        "# Training loop\n"
      ],
      "metadata": {
        "id": "2dqlGbnA7XZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the curve of training and test losses"
      ],
      "metadata": {
        "id": "T_sT73t89yzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please plot your training and test losses against training epochs (or every say 1000 iterations) so you can make sure the model is trained properly.\n",
        "# The optimization has converged, and there is not an obvious overfitting issue."
      ],
      "metadata": {
        "id": "lwLbwR_59yFQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b50525"
      },
      "source": [
        "## Generate images with the CNN model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdb7f2d7"
      },
      "source": [
        "\n",
        "# at each step, the input is the incomplete image. To generate the image:\n",
        "# * Run the CNN to predict the next pixel.\n",
        "# * Append it to the incomplete\n",
        "# * loop over the two previous steps\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot your generated images here"
      ],
      "metadata": {
        "id": "D3A-_7QN7BqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}